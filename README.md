# SOCIAL
A chat bot based off the Selena 1 architecture

INTRODUCTION
============

I started my work on the SELENA architecture, its most basic components, when I completed my first graduate courses in AI and Robotics back in 2007. I wanted to find a way
to combine semantic networks, which I had just learned about but seemed so fixed, graph theory which was so robust but still fixed, and first and second order logic which I had just
learned about. I started working on a graph structure that included inference and logical operators on its edges, essentially a semantic network that could capture
mathematical and propositional logic. I thought the idea was amazing and as I started my work after getting my bachelors (with graduate work classes playing a large part ironically)
I leanred a new method behind planning software at my new job at a prominent government contracctor, Requirements documentaiton. So I started to set out to write a general description
of what a fully autonomous, self-instructing AI would require, and writing a a whole mess of technical requirements that would have to be met over time. This was the firs version
of SELENA that I created, named after a friendly Colombian bartender that inspired me, and began what the present work is today.

After completing my masters degree in Computer Science at Drexel University, partially completing a thesis on Natural Language Processing, and getting a very long education
with concentrations in both Computer Graphics and Artifial Intelligencec. I finished this degree in 2017 and began to start thinking more deeply about AI when introduced
into more detail about Neural Networks, Deep Learning, Machine Learning, and algorithms like MapReduce.

I created a second revision of SELENA with the idea that I could incorporate everything I wanted into the data structure. I could make it have different cortexes like the
human brain, referred to as "cores" in SELENA, neurotransmitters to facilitate neuro network acctivity, and still maintain the M-Graph data structure I had originally
conceived. Other organizations of the affectors and sensors were disjoint from the vcore architecture and although I had a lot of good ideas, the entire paper was 
completely disjoint and dysfunctional. I rereleaesd it as SELENA version 2 as a kindle book on Amazon.combine

As time went in 2021, 2022, and forward I began to think more about the way neurotransmitters play in the brain due to my own personal experiences and experiences of my
friends, associates, and colleagues. I came up with a novel idea of how to represent them for training purposes in a neural netowrk and the reserach that I am devoting ano
another part of my time to, SELENA 2, is based off that very research. SELENA 2 delves deeply into the way neuroscientists believe neurotransmitters play in regulating moood,
communication, and training in the brain. I however found this year as I began to work on this new reserach (2022) that I had to have a better framework to build it upon
then the framework we currently use for Deep Learning and ARtificial Neural Networks. THese architectures are so specialized and rigid, and after watching presentations on
the present state of AI< and also the many incredible accomplishments we have achieved, I was inspired to revisit SELENA 1 and create this current revision, revision 3.

Revision 3 of SELENA incorporates something that was mid revision 2 and revision 3, the idea that the brain uses four fundamental algorithms to maintain its network.
THese algorithms are SORT, INTEGRATION, DISINTEGRATION, and SEARCH. It was my belief that via these four algorithms and the right data structure, any function that could 
be performed necessary for a neural network could be done. I just needed to write the algorithm and the data structure. :-)

At present time of the four central algorithms that govern all brain function, two have been partially flushed out, with a further more important subalgorithm, a "hinting"
algorithm under way as the data structure of the M-Graph, now known as a Meta-Graph has evolved. This paper draws from every paper I Have evver wrote on AI and every thought
I have had about AI except the work done in SELENA 2. My strong interest in MapReduce and its demonstrated incredible potential has convinced me that a similar algorithm
that occurs over a neural-netowrk likedata structure is the key to implementation of the majority of the four key algorithms. 

The requirements have been rewritten and reorganizing, but the research apper is still an ongoing project. The data strucfture is still being flushed out as the algorithms are
and we encourage any researchers or really anybody elses thoguhts on the entire subject. I've included my readings about markers in AI for natural language, researched the way 
chatbots are coded and trained, investigated a dozen different foreign language grammars over the last few years, and included in SELENA my thoughts on Context-Free Grammars
vs. COntext-Given Grammars ( what I denote as the grammars tha tnatural languages used and their parsing implementations).  I included this information before workiing on SELENA
revision 3, after discussing with her differences in the grammars of English, German, and Russian. My aunt earned her Ph.D. as a fullbright scholar and wrote her doctoral thesis
in German, not her native language, and studied and taught German in Russia. 

Finally I chose Set-Theory as the basis of the language of the nodes in teh neural network of the Meta-Graph. Through set-theory and first-order logic operations, virtually any
logical statement can be represented. IT is important to enforce this global sense and so I abandoned the use of direct inference and logical operators for the a more simplified
languagee including set theory and first order logic. ALso, I Found that the ideas behind the Lambda Calculus and abstractiona nd binding are incredibly important in the way
we think and process ideas. We are constantly abstracvting and connevvting abstracvtions to oother abstraccvtions, then diving into abstractions to find sets of more diverse
abstractions. Set THeory provides for the most simple and useful model of abstraction, and combinding it with the operations of first-order logic and general ideas of the 
lambda calculus will give us a good model to model the human brain from. Also, according to my understanding of ZFC, any mathematical system can be constructed using Set Theory
as its foundation, which tends me to believe that this data structure, without direcct proof, is Turing Complete.

CHATBOT
=======

The present goal of this repository is to first of all, finish the research for SELENA 1. THis means implementing a simple chatbot that uses a language parsing mechanism as
its only sensor and an output stream as its own effecctor. As the SELENA 1 research paper is completed (requirements, algorithms flushefd out, data structures adjusted, 
method disk/database storage divined, etc. ) I hope the abilities of this simple chatbot will grow to show the incredible versatility I believe SELENA 1 to have so far,
My hopes are for it to outperform anything that's been done before and to operate over global training than a dedicated neural net. My plans to train it involve writing a simple
web scraper for it and have it start reading and educating itself. I believe the SELENA 1 architecture can teach itself almost completely autonomously, even in a chatbot once it
has been trained how to read a natural langauge and can begin scraping articles. But the work is not yet done, so we shall see how things go.

In summary I;d like to finally present this research to the public and get some public feedback on it. It has been private for far too long and there is far too much work to be 
done to leave it in my own hands. Good luck and happy chatting.

2022-10-16 10:47 PM EDT 

This is the initial posting of the repository for the chatbot "SOCIAL" designed after the ongoing WIP SELENA 1 architecture for Artificial Intelligence
to the public. This repository includes ongoing research that is WIP by Twilight Raven Games LLC under GPL 3.0 that is included in the docx
Word documents included for download with this repository. 

CHANGELOG
=========